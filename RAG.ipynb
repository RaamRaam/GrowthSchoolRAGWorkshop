{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28148f38-49c1-42aa-be4c-ab16d784770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from PyPDF2 import PdfReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27095bd-70de-400f-b8aa-42612721c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    content = \"\"\n",
    "    for page in reader.pages:\n",
    "        content += page.extract_text() + \"\\n\"  # Append text from each page\n",
    "    return content\n",
    "\n",
    "def split_text_into_chunks(text, chunk_size=300):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "\n",
    "def embed_text_chunks(chunks, embedding_model_name=\"all-MiniLM-L6-v2\"):\n",
    "    model = SentenceTransformer(embedding_model_name)\n",
    "    embeddings = model.encode(chunks, convert_to_numpy=True, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def build_faiss_index(embeddings):\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e806e8-7bda-450f-969d-de8c48b1125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"documents/LLM.pdf\"  # Replace with your PDF file path\n",
    "pdf_content = read_pdf(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5206f697-b513-46f9-ae01-fa9a9783638f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe02953-2634-4a3f-afb6-948ea26ec25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_text_into_chunks(pdf_content, chunk_size=64)\n",
    "embedding_model_name = \"all-mpnet-base-v2\"\n",
    "embeddings = embed_text_chunks(chunks, embedding_model_name)\n",
    "chunk_data = {\"chunks\": chunks, \"embeddings\": embeddings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d3097-5554-4310-b5f3-28ed0f444314",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index = build_faiss_index(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c032a-325e-4b6e-8c2b-56eae55270bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Evolution of Large Language Models\"  # Your search query\n",
    "query_embedding = SentenceTransformer(embedding_model_name).encode([query], convert_to_numpy=True)\n",
    "distances, indices = faiss_index.search(query_embedding, k=3)  # Retrieve top-3 closest chunks\n",
    "response_chunks='\\n'.join([chunks[i] for i in indices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898cab4f-69b0-4e39-8f05-2744d529fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_model(response_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed146cb-c239-4528-a6cc-b9ce04f8be28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b378b-4390-4b4d-96a3-a13d9e511e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ollama.com/download\n",
    "# https://github.com/ollama/ollama-python\n",
    "\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "\n",
    "response_chunks='\\n'.join([chunks[i] for i in indices[0]])\n",
    "response: ChatResponse = chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': f\"Answer {query} from(do not hallucinate) in 100 words  {response_chunks}\"\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
