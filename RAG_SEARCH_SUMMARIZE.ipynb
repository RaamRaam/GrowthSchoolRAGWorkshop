{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c7ee49",
   "metadata": {},
   "source": [
    "# PDF Text Embedding, FAISS Search, and Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fc5516",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Extract text from a PDF file.\n",
    "2. Split text into manageable chunks for embedding.\n",
    "3. Generate embeddings with SentenceTransformers.\n",
    "4. Use FAISS for similarity-based text search.\n",
    "5. Summarize retrieved content using a summarization model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c767b29",
   "metadata": {},
   "source": [
    "## Step 1: Extract Text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3490f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    content = \"\"\n",
    "    for page in reader.pages:\n",
    "        content += page.extract_text() + \"\\n\"  # Append text from each page\n",
    "    return content\n",
    "\n",
    "file_path = \"documents/LLM.pdf\"  # Replace with your PDF file path\n",
    "pdf_content = read_pdf(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee702ea",
   "metadata": {},
   "source": [
    "## Step 2: Split Text into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f5bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, chunk_size=300):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "chunks = split_text_into_chunks(pdf_content, chunk_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965b749",
   "metadata": {},
   "source": [
    "## Step 3: Embed Text Chunks Using SentenceTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffed7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "def embed_text_chunks(chunks, embedding_model_name=\"all-MiniLM-L6-v2\"):\n",
    "    model = SentenceTransformer(embedding_model_name)\n",
    "    embeddings = model.encode(chunks, convert_to_numpy=True, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "embedding_model_name = \"all-mpnet-base-v2\"\n",
    "embeddings = embed_text_chunks(chunks, embedding_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cbe57",
   "metadata": {},
   "source": [
    "## Step 4: Build a FAISS Index for Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "def build_faiss_index(embeddings):\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "faiss_index = build_faiss_index(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b0622",
   "metadata": {},
   "source": [
    "## Step 5: Query the FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea6f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Foundation Language Models vs. Fine-Tuned Language Models\"  # Your search query\n",
    "query_embedding = SentenceTransformer(embedding_model_name).encode([query], convert_to_numpy=True)\n",
    "\n",
    "# Retrieve top-3 closest chunks\n",
    "distances, indices = faiss_index.search(query_embedding, k=3)\n",
    "response_chunks = '\\n'.join([chunks[i] for i in indices[0]])\n",
    "\n",
    "print(response_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24414e62",
   "metadata": {},
   "source": [
    "## Step 6: Summarize Retrieved Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5afd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarize_model = pipeline(\"summarization\", model=\"models/bart-large-cnn\")\n",
    "summary = summarize_model(response_chunks, max_length=100, min_length=30, do_sample=False)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
