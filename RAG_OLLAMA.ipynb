{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67dcaf8",
   "metadata": {},
   "source": [
    "# PDF Text Embedding, FAISS Search, and Ollama API for QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae76a0",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates:\n",
    "1. Extracting text from a PDF file.\n",
    "2. Splitting text into manageable chunks for embedding.\n",
    "3. Generating embeddings with SentenceTransformers.\n",
    "4. Using FAISS for similarity-based text search.\n",
    "5. Using Ollama API to answer queries based on the retrieved content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5facef0",
   "metadata": {},
   "source": [
    "## Step 1: Extract Text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3229d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    content = \"\"\n",
    "    for page in reader.pages:\n",
    "        content += page.extract_text() + \"\\n\"  # Append text from each page\n",
    "    return content\n",
    "\n",
    "file_path = \"documents/LLM.pdf\"  # Replace with your PDF file path\n",
    "pdf_content = read_pdf(file_path)\n",
    "len(pdf_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d045872",
   "metadata": {},
   "source": [
    "## Step 2: Split Text into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e5aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, chunk_size=300):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "chunks = split_text_into_chunks(pdf_content, chunk_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e429742",
   "metadata": {},
   "source": [
    "## Step 3: Embed Text Chunks Using SentenceTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dda483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "def embed_text_chunks(chunks, embedding_model_name=\"all-MiniLM-L6-v2\"):\n",
    "    model = SentenceTransformer(embedding_model_name)\n",
    "    embeddings = model.encode(chunks, convert_to_numpy=True, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "embedding_model_name = \"all-mpnet-base-v2\"\n",
    "embeddings = embed_text_chunks(chunks, embedding_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f826529a",
   "metadata": {},
   "source": [
    "## Step 4: Build a FAISS Index for Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "def build_faiss_index(embeddings):\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "faiss_index = build_faiss_index(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b810578",
   "metadata": {},
   "source": [
    "## Step 5: Query the FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Foundation Language Models vs. Fine-Tuned Language Models\"  # Your search query\n",
    "query_embedding = SentenceTransformer(embedding_model_name).encode([query], convert_to_numpy=True)\n",
    "\n",
    "# Retrieve top-3 closest chunks\n",
    "distances, indices = faiss_index.search(query_embedding, k=3)\n",
    "response_chunks = '\\n'.join([chunks[i] for i in indices[0]])\n",
    "\n",
    "print(response_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3de652",
   "metadata": {},
   "source": [
    "## Step 6: Summarize Retrieved Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarize_model = pipeline(\"summarization\", model=\"models/bart-large-cnn\")\n",
    "summary = summarize_model(response_chunks, max_length=100, min_length=30, do_sample=False)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7cc3bb",
   "metadata": {},
   "source": [
    "## Step 7: Answer Questions Using Ollama API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68dba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ollama SDK: https://ollama.com/download\n",
    "# Documentation: https://github.com/ollama/ollama-python\n",
    "\n",
    "from ollama import chat, ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': f\"Answer {query} from (do not hallucinate) in 100 words {response_chunks}\"\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
